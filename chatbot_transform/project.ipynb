{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기, 확인, 전처리\n",
    "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\t\n",
    "\n",
    "공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description.\n",
    "\n",
    "인공데이터입니다. 일부 이별과 관련된 질문에서 다음카페 \"사랑보다 아름다운 실연( http://cafe116.daum.net/_c21_/home?grpid=1bld )\"에서 자주 나오는 이야기들을 참고하여 제작하였습니다. \n",
    "\n",
    "가령 \"이별한 지 열흘(또는 100일) 되었어요\"라는 질문에 챗봇이 위로한다는 취지로 답변을 작성하였습니다.\n",
    "\n",
    "챗봇 트레이닝용 문답 페어 11,876개\n",
    "\n",
    "일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n",
      "None\n",
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n",
      "label\n",
      "0    5290\n",
      "1    3570\n",
      "2    2963\n",
      "Name: count, dtype: int64\n",
      "                         Q                          A  label\n",
      "5290     1000일 만난 여자친구와 이별         더 오래 만날 사람 만날 거예요.      1\n",
      "5291       10년 연애. 헤어졌습니다.              더 공허함이 크시겠네요.      1\n",
      "5292  10년 연애사 되돌아보니 다 부질없네           더 좋은 사람 만나실 거예요.      1\n",
      "5293              10년 연예의끝               더 마음이 허하겠어요.      1\n",
      "5294           10년만나다 헤어지네  충분히 슬퍼하고 충분히 아파하다가 이겨내세요.      1\n",
      "...                    ...                        ...    ...\n",
      "8855                 힘듭니다.    어떤 말도 위로가 되지 않겠지만 힘내세요.      1\n",
      "8856          힘이 될런지 모르겠지만    어떤 말도 위로가 되지 않겠지만 힘내세요.      1\n",
      "8857                 힘이 드네    어떤 말도 위로가 되지 않겠지만 힘내세요.      1\n",
      "8858                 힘이 없어                      힘내세요!      1\n",
      "8859           힘이드네.여자들이란.    어떤 말도 위로가 되지 않겠지만 힘내세요.      1\n",
      "\n",
      "[3570 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "raw_dt = pd.read_csv('ChatbotData .csv')\n",
    "print(raw_dt.head())\n",
    "print(raw_dt.info())\n",
    "print(raw_dt.isnull().sum())\n",
    "print(raw_dt.label.value_counts())\n",
    "print(raw_dt[raw_dt.label == 1])\n",
    "\n",
    "data = raw_dt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 학생입니다 . 여러분은요 ? aa 2\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거, 영문자가 들어가 있으니 소문자화 시킴\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # 숫자, 영어, 한국어, 구두점 을 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^1-9a-zA-Z가-힣?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "\n",
    "# 테스트 예제\n",
    "example_sentence = \"저는 학생입니다. 여러분은요? AAㅇ    2\"\n",
    "print(preprocess_sentence(example_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n",
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수 적용, 시리즈를 리스트로 변환 \n",
    "q_pre = data['Q'].apply(preprocess_sentence).tolist()\n",
    "a_pre = data['A'].apply(preprocess_sentence).tolist()\n",
    "print('전체 샘플 수 :', len(q_pre))\n",
    "print('전체 샘플 수 :', len(a_pre))\n",
    "print('전처리 후의 22번째 질문 샘플: {}'.format(q_pre[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(a_pre[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8158]\n",
      "END_TOKEN의 번호 : [8159]\n",
      "8160\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "# 영어가 아니여도 작동함\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(q_pre + a_pre, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "# 디코더의 문장 생성 과정에서 사용할 '시작 토큰'과 '종료 토큰'에 대해서도 임의로 단어장에 추가하여서 정수를 부여해 줍니다. \n",
    "# 이미 생성된 단어장의 번호와 겹치지 않도록 각각 단어장의 크기와 그보다 1이 큰 수를 번호로 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8160\n",
      "필터링 후의 질문 샘플 개수: 11817\n",
      "필터링 후의 답변 샘플 개수: 11817\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 25\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "q_token, a_token = tokenize_and_filter(q_pre, a_pre)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(q_token)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(a_token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교사 강요를 통한 병렬 처리\n",
    "# 질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다. 이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값, answers[:, 1:]를 디코더의 레이블로 사용\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': q_token, # 리스트\n",
    "        'dec_inputs': a_token[:, :-1] # 리스트\n",
    "    },\n",
    "    {\n",
    "        'outputs': a_token[:, 1:] # 정답 레이블로 쓰임 \n",
    "    },\n",
    "))\n",
    "\n",
    "# cache()는 데이터셋을 메모리에 캐싱하여 I/O 오버헤드를 줄입니다.\n",
    "# shuffle(BUFFER_SIZE)는 데이터를 섞어서 훈련 중 과적합을 방지합니다.\n",
    "# batch(BATCH_SIZE)는 데이터를 배치 단위로 묶어줍니다.\n",
    "# prefetch(tf.data.experimental.AUTOTUNE)는 데이터 로딩과 모델 훈련을 병렬로 수행하여 훈련 속도를 높입니다.\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs (inputs):\n",
      " [[8158 2489 2486 ...    0    0    0]\n",
      " [8158   88 4427 ...    0    0    0]\n",
      " [8158  116    6 ...    0    0    0]\n",
      " ...\n",
      " [8158  221  948 ...    0    0    0]\n",
      " [8158   77 5178 ...    0    0    0]\n",
      " [8158  968  599 ...    0    0    0]]\n",
      "Decoder Inputs (dec_inputs):\n",
      " [[8158 6290    1 ...    0    0    0]\n",
      " [8158 7414   33 ...    0    0    0]\n",
      " [8158 4922  866 ...    0    0    0]\n",
      " ...\n",
      " [8158  307   82 ...    0    0    0]\n",
      " [8158  180 5032 ...    0    0    0]\n",
      " [8158   23 7115 ...    0    0    0]]\n",
      "Outputs (outputs):\n",
      " [[6290    1 8159 ...    0    0    0]\n",
      " [7414   33 3960 ...    0    0    0]\n",
      " [4922  866 1381 ...    0    0    0]\n",
      " ...\n",
      " [ 307   82  229 ...    0    0    0]\n",
      " [ 180 5032 1385 ...    0    0    0]\n",
      " [  23 7115 7934 ...    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 03:13:07.398219: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# 병럴 처리된 데이터셋 구조와 샘플 데이터 확인\n",
    "for batch in dataset.take(1):\n",
    "    inputs, outputs = batch\n",
    "    print(\"Inputs (inputs):\\n\", inputs['inputs'].numpy())\n",
    "    print(\"Decoder Inputs (dec_inputs):\\n\", inputs['dec_inputs'].numpy())\n",
    "    print(\"Outputs (outputs):\\n\", outputs['outputs'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구현 & 학습\n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\t\n",
    "\n",
    "구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "# sin, cos를 쓰는 이유는 주기성이 다음 장점을 가지기 때문 \n",
    "# 1. 임베딩 벡터가 커져도 중복되지 않게 값을 부여하기 위함 \n",
    "# 2. 임베딩 벡터의 상대적인 거리를 표현하기 위함 \n",
    "# 3. 값들이 크기가 비슷해야 학습이 잘 됨 [-1, 1] \n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if isinstance(inputs, tf.SparseTensor): # 라이브러리 버전 차이로 인해 추가 - sparseTensor를 denseTensor로 변환\n",
    "          inputs = tf.sparse.to_dense(inputs) \n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  # [-1] 는 마지막 차원의 크기를 의미\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32) # 행렬의 마지막 차원 (depth) \n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9) # 패딩된 위치에 큰 음수로 곱함 -> softmax 함수를 지나면 행렬의 해당 위치가 0에 가까워짐\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티 헤드 어텐션\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    # tf.input 은 batch_size를 생략하는게 일반적 -> 정의된 차원보다 입력차원이 크면 맨 앞의 차원을 batch_size로 인식\n",
    "    # tf.reshape는 batch_size를 생략하지 못함\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth)) # [batch_size, sequence_length, num_heads, depth]\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention) # [batch_size, seq_len_q, d_model], 늘어난 차원을 d_model 차원으로 다시 줄여줍니다\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 패딩 토큰(Padding token) 을 이용한 패딩 마스킹(Padding Masking) - todo \n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # mask의 차원을 확장하여 (batch_size, 1, 1, sequence_length) 형태로 변환, 2번째와 3번째 차원에 1을 추가\n",
    "  # 확장하는 이유 : 텐션 메커니즘에서 패딩 토큰이 학습에 영향을 미치지 않도록 하기 위해 사용 : 이해 못함 \n",
    "  return mask[:, tf.newaxis, tf.newaxis, :] # tf.newaxis는 텐서플로에서 새로운 차원을 추가하는 데 사용되는 방법\n",
    "\n",
    "# 패딩 마스킹이 동작하는지 확인, 0 (패딩)인 단어들은 1로 찾음\n",
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1] # 입력 텐서의 크기에서 seq_len을 받아옴 (batch_size, seq_len)\n",
    "  # tf.linalg.band_part(matrix, num_lower, num_upper)는 대각선 부분 밴드의 값을 유지하고, 나머지 값을 0으로 설정합니다.\n",
    "  ## num_lower, upper에는 대각선 이후에 유지하고 싶은 대각선의 수를 의미하는 것 같음\n",
    "  ## -1은 대각선을 포함하는 모든 요소를 유지합니다. \n",
    "  ## 0은 대각선만 유지하고, 아래의 모든 요소를 0으로 설정\n",
    "  # 1-... 을 하면 대각선을 기준으로 위쪽을 0으로 만들고, 아래쪽을 1로 만듭니다.\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x) # 입력 시퀀스의 패딩 토큰(보통 0으로 표현됨)을 마스킹하기 위해 패딩 마스크도 함께 사용\n",
    "  return tf.maximum(look_ahead_mask, padding_mask) # 두 마스크 중 하나라도 1인 위치를 1로 설정\n",
    "\n",
    "# 룩 어헤드 마스킹이 동작하는지 확인, 1인 위치는 마스킹된 위치\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))\n",
    "\n",
    "# 패딩 토큰이 존재하는 경우 확인 \n",
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 층을 임베딩 층(Embedding layer) 과 포지셔널 인코딩(Positional Encoding) 을 연결하고, 사용자가 원하는 만큼 인코더 층을 쌓음\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의 및 학습 \n",
    "# 앞서 사용한 인코더 층 함수와 디코더 층 함수를 사용하여 트랜스포머 함수를 정의\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\") # 가변 길이의 1차원 정의 (batch_size, sequence_length)\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None), # (batch_size, 1, 1, sequence_length)\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None), # (batch_size, 1, sequence_length, sequence_length)\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_padding_mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,143,168</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ enc_padding_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ look_ahead_mask     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_padding_mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,670,528</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ look_ahead_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ dec_padding_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,120</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8160</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_padding_mask    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,143,168\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ enc_padding_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ look_ahead_mask     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_padding_mask    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,670,528\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ look_ahead_mask[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ dec_padding_mask… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ outputs (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m2,097,120\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m8160\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,910,816</span> (33.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,910,816\u001b[0m (33.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,910,816</span> (33.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,910,816\u001b[0m (33.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이해함 아마도\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원, 단어 벡터의 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE, # 단어장의 크기\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1)) #?\n",
    "  \n",
    "  # from_logit : y_pred가 확률 분포가 아닌 로짓(logit)일 경우 True로 설정\n",
    "  # reduction='none': 각 샘플별로 손실을 계산합니다. 따라서 배치 내의 각 샘플에 대해 개별 손실 값을 반환\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred) \n",
    "\n",
    "  # tf.not_equal(y_true, 0): y_true에서 값이 0이 아닌 위치는 True, 0인 위치는 False로 표시\n",
    "  # tf.cast(..., tf.float32): True는 1.0으로, False는 0.0으로 변환\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  # loss와 mask를 곱하여, 실제 레이블이 0인 위치의 손실 값을 0으로 만듭니다. 이는 패딩된 위치의 손실을 무시하기 위함\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  # 평균 손실 반환 : 각 샘플의 손실의 평균을 구함\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 커스텀된 학습률 - 이해함\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  # d_model은 모델의 단어 임베딩 차원 수\n",
    "  # warmup_steps는 학습률이 증가하는 단계의 수\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)  # 추가, 여기서 step을 float32로 변환\n",
    "    arg1 = tf.math.rsqrt(step) # 현재 학습 단계의 제곱근의 역수를 계산\n",
    "    arg2 = step * (self.warmup_steps**-1.5) # 현재 학습 단계와 warmup_steps의 -1.5제곱을 곱한 값을 계산\n",
    "\n",
    "    # 최종 학습률은 d_model의 제곱근의 역수와 arg1과 arg2 중 작은 값을 곱하여 계산됩니다. 이는 초기 학습 단계에서는 학습률이 점진적으로 증가하고, 이후에는 감소하는 형태의 스케줄을 만듭니다\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# todo 이해 못함\n",
    "# 예상 y_true : 디코더의 출력 : [단어1, 단어2, 단어3, 단어4, end_token]\n",
    "# 예상 y_pred : [[단어1의 확률 분포], [단어2의 확률 분포], [단어3의 확률 분포], [단어4의 확률 분포], [end_token의 확률 분포]]\n",
    "# end_token을 제외하고 정답과 예측의 분포가 일치하는지 확인하는게 좋으므로, reshape을 통해 end_token을 제외하고 shape을 맞춰준거 같음. 여기서 reshape가 어떻게 작동하는지는 모르겠음\n",
    "# 보통 reshape는 차원의 요소수를 보존한 상태에서 차원을 줄이거나 늘리는데 사용되는데, 여기서는 차원의 요소수를 줄이는데 사용된건가? 이해 안됨 \n",
    "def accuracy(y_true, y_pred): \n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1)) # 출력의 shape과 맞춤, batch_size, MAX_LENGTH - 1, 디코더의 출력에 end_token이 있으므로 이를 제외\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718853195.102911   80910 service.cc:145] XLA service 0x7f86e403e8a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718853195.103027   80910 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-06-20 03:13:15.320936: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1718853195.695261   80910 assert_op.cc:38] Ignoring Assert operator compile_loss/loss_function/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-06-20 03:13:16.062079: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718853201.993548   84224 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_21', 456 bytes spill stores, 408 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.001061   84206 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_214', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.019694   84205 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_36', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.079491   84200 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_21', 172 bytes spill stores, 172 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.410191   84213 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_36', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.561259   84218 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_210', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.574839   84199 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_36', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.710138   84217 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_137', 260 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.773319   84215 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_217', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.912838   84204 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_153', 204 bytes spill stores, 160 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853202.973776   84212 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_153', 412 bytes spill stores, 412 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853203.696787   84209 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853204.050907   84218 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_52', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853204.136184   84208 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 468 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853204.951924   84196 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_52', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853204.977920   84198 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853205.136520   84206 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853205.214232   84218 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853205.279210   84223 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853205.287367   84200 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853205.325732   84203 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853205.329740   84216 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  3/185\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.0000e+00 - loss: 2.6476 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718853214.154948   80910 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0204 - loss: 2.4936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1718853215.818013   80911 assert_op.cc:38] Ignoring Assert operator compile_loss/loss_function/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1718853221.055759   84814 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853221.066880   84832 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_21', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853221.282400   84833 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_21', 468 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853221.315692   84820 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 468 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853221.325593   84819 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_52', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853221.740361   84833 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_21', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.074025   84829 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_214', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.202098   84824 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_10', 28 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.230053   84816 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_36', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.279951   84815 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 68 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.326514   84821 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.493247   84817 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_137', 260 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.573835   84837 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.574403   84831 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.635573   84815 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_36', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.865876   84830 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_217', 32 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853222.929150   84807 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853223.008112   84834 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_137', 84 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853223.123163   84821 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_52', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853223.185028   84814 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853223.335424   84823 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_137', 84 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853223.666633   84829 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_217', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853224.304065   84829 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_151', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853224.374853   84818 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_217', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853224.461652   84814 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_210', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853224.492899   84820 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_153', 576 bytes spill stores, 504 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853224.571828   84808 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_50', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853224.630906   84819 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_210', 32 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1718853224.895503   84806 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_210', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 101ms/step - accuracy: 0.0214 - loss: 2.4889\n",
      "Epoch 2/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0803 - loss: 2.0103\n",
      "Epoch 3/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0816 - loss: 1.6690\n",
      "Epoch 4/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0861 - loss: 1.5149\n",
      "Epoch 5/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0925 - loss: 1.4254\n",
      "Epoch 6/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0996 - loss: 1.3298\n",
      "Epoch 7/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1090 - loss: 1.2112\n",
      "Epoch 8/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1227 - loss: 1.0941\n",
      "Epoch 9/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1370 - loss: 0.9787\n",
      "Epoch 10/10\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1518 - loss: 0.8290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f884d4915d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 진행 - 이해함 \n",
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1) # verbose 로그의 상세도를 제어, 1 = progress bar, 0 = silent, 2 = one line per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 테스트\n",
    "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\t\n",
    "\n",
    "한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭\n",
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 좋은 아침입니다.\n",
      "출력 : 좋은 생각이에요 .\n",
      "\n",
      "\n",
      "입력 : 공감이 가는 말이네요.\n",
      "출력 : 다른 곳에 쓰려고 운을 아껴뒀나봐요 .\n",
      "\n",
      "\n",
      "입력 : 무슨 생각을 하고 있어요?\n",
      "출력 : 아직 모르겠어요 .\n",
      "\n",
      "\n",
      "입력 : 오늘 날씨가 어때요?\n",
      "출력 : 잘 될 거예요 .\n",
      "\n",
      "\n",
      "입력 : 너무 피곤해요.\n",
      "출력 : 좀 더 일찍 주무세요 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentence = ['좋은 아침입니다.', '공감이 가는 말이네요.', '무슨 생각을 하고 있어요?', '오늘 날씨가 어때요?', '너무 피곤해요.']\n",
    "\n",
    "for sentence in test_sentence:\n",
    "    sentence_generation(sentence)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
